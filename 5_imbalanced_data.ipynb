{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41cb6589",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/issondl/from-data-to-solution-2021/blob/main/5_imbalanced_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Zf6rdRc0sCr",
   "metadata": {
    "id": "5Zf6rdRc0sCr"
   },
   "source": [
    "# Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SjWtTaLX0kac",
   "metadata": {
    "id": "SjWtTaLX0kac"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a558e6-ebc1-4f4e-b5be-ad279c66383c",
   "metadata": {
    "id": "d8a558e6-ebc1-4f4e-b5be-ad279c66383c"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "from keras import backend as K\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import average_precision_score, roc_auc_score, roc_curve,\\\n",
    "precision_recall_curve, plot_precision_recall_curve, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
    "from tensorflow.keras.models import Model\n",
    "from tqdm import tqdm\n",
    "\n",
    "random.seed(2021)\n",
    "set_verbosity(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z8CWW15p1LZO",
   "metadata": {
    "id": "z8CWW15p1LZO"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d188b56-405b-4e3e-b4de-2378c10fcb7f",
   "metadata": {
    "id": "6d188b56-405b-4e3e-b4de-2378c10fcb7f"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "CSV_FILE = os.path.join(DATA_DIR, 'binary_biased_wsweights_29.csv')\n",
    "IMAGES_ARCHIVE_FILE = os.path.join(DATA_DIR, 'nih_chest_xray_single_9c_256x256.tar.gz')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')\n",
    "\n",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HDk6WAV91Oyb",
   "metadata": {
    "id": "HDk6WAV91Oyb"
   },
   "source": [
    "## Check for acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7fde9-9eb1-4ee1-bb94-0e23583a5456",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02e7fde9-9eb1-4ee1-bb94-0e23583a5456",
    "outputId": "db2eeb25-189d-4ed5-ff04-5466faf22bcb"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005de15-ff10-40b5-9e3a-7776263b2b4f",
   "metadata": {
    "id": "1005de15-ff10-40b5-9e3a-7776263b2b4f"
   },
   "source": [
    "## Get files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a44e8-f014-4666-a1b4-ae8bad970d03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b9a44e8-f014-4666-a1b4-ae8bad970d03",
    "outputId": "784c20ba-1e40-4443-bef7-3e09290738bc"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_FILE):\n",
    "    ! gdown --id 13e8MugScdW2LeGlqZornhYJ3pkRl78QK -O $CSV_FILE\n",
    "else:\n",
    "    print('CSV file ({}) already exists.'.format(CSV_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02cbc3-1759-4ff5-9d80-4b1449620a34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca02cbc3-1759-4ff5-9d80-4b1449620a34",
    "outputId": "a95d4e35-d1d8-4294-be64-b5e9df24c7bc"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_ARCHIVE_FILE):\n",
    "    ! gdown --id 1Cg7dbE1tWSBvdTfGc0G272SA_j_XocOW -O $IMAGES_ARCHIVE_FILE\n",
    "else:\n",
    "    print('Images archive file ({}) already exists.'.format(IMAGES_ARCHIVE_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e6a44-e2fb-4131-a2b8-80d7f275397a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b7e6a44-e2fb-4131-a2b8-80d7f275397a",
    "outputId": "dea14ad2-1965-47b3-a559-b0421307c6e5"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_DIR):\n",
    "    ! tar -xzf $IMAGES_ARCHIVE_FILE\n",
    "    print('Unpacked to {}'.format(IMAGES_DIR))\n",
    "else:\n",
    "    print('Images have already been unpacked ({}).'.format(IMAGES_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7m07VkZa1fTz",
   "metadata": {
    "id": "7m07VkZa1fTz"
   },
   "source": [
    "## Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e63851-6458-4de5-aab7-619ff7dc2c64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 451
    },
    "id": "54e63851-6458-4de5-aab7-619ff7dc2c64",
    "outputId": "a42aba70-adca-4aef-ec6a-6a71b0f279e9"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_FILE)\n",
    "df[df.columns[::-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c2a26-2a30-4add-af30-66b4154c958d",
   "metadata": {
    "id": "b90c2a26-2a30-4add-af30-66b4154c958d"
   },
   "source": [
    "## Prepare Data for Training and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CsBr5qGNbqAd",
   "metadata": {
    "id": "CsBr5qGNbqAd"
   },
   "source": [
    "We will be doing binary classification: No Finding vs Pneumothorax.\n",
    "\n",
    "Tasks:\n",
    "\n",
    "\n",
    "1.   Make sure there are no rows with category that is not used.\n",
    "2.   Drop redundant columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e6e690-f29c-40a1-9c5a-2147e868a2aa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82e6e690-f29c-40a1-9c5a-2147e868a2aa",
    "outputId": "ac066cea-844a-4282-c55d-85a02b273667"
   },
   "outputs": [],
   "source": [
    "## We will be doing binary classification: No Finding vs Pneumothorax.\n",
    "## Make sure there are no rows with category that is not used.\n",
    "## Drop redundant columns. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42430bf-cfae-491b-ad05-fc91e8778645",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "f42430bf-cfae-491b-ad05-fc91e8778645",
    "outputId": "c9af5965-7108-4fb6-cf42-8de9ac697b94"
   },
   "outputs": [],
   "source": [
    "LABELS = df.columns[4]\n",
    "LABELS # 'No Finding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37788204-24c1-457a-92e8-3436b393aa46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "37788204-24c1-457a-92e8-3436b393aa46",
    "outputId": "7124c481-0a33-461c-d0fe-173b76f52810"
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.3\n",
    "\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "train_df, tmp_df = train_test_split(\n",
    "    df,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=df['Finding Labels']\n",
    ")\n",
    "\n",
    "half = int(len(tmp_df)/2)\n",
    "\n",
    "# Testing set (top half of the remainder)\n",
    "test_df = tmp_df[:half]\n",
    "\n",
    "# Validation set (bottom one)\n",
    "val_df = tmp_df[-half:]\n",
    "\n",
    "print('All: {}'.format(len(df)))\n",
    "print('Train: {}'.format(len(train_df)))\n",
    "print('Val: {}'.format(len(val_df)))\n",
    "print('Test: {}'.format(len(test_df)))\n",
    "\n",
    "train_df.groupby('Patient Gender')['Finding_ID'].value_counts().unstack(0).plot.barh(figsize=(5,5))\n",
    "val_df.groupby('Patient Gender')['Finding_ID'].value_counts().unstack(0).plot.barh(figsize=(5,5))\n",
    "test_df.groupby('Patient Gender')['Finding_ID'].value_counts().unstack(0).plot.barh(figsize=(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a840309c-7d95-4448-8f3b-695fb04ca755",
   "metadata": {
    "id": "a840309c-7d95-4448-8f3b-695fb04ca755"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "IMAGE_SIZE = [240, 240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0b6c1-46c0-4c20-b028-6377ddd09182",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eca0b6c1-46c0-4c20-b028-6377ddd09182",
    "outputId": "da1203e0-7a69-43e6-97f5-2aaa37f6661b"
   },
   "outputs": [],
   "source": [
    "def get_train_generator(df, x_col, y_cols, batch_size, target_image_size, seed=2021):\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.15,\n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.05,\n",
    "        horizontal_flip=True, \n",
    "        vertical_flip=False, \n",
    "        fill_mode='reflect'\n",
    "    )\n",
    "\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=df,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode='raw',\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        seed=seed,\n",
    "        target_size=target_image_size,\n",
    "    )\n",
    "    \n",
    "    return generator\n",
    "\n",
    "train_generator = get_train_generator(\n",
    "    df = train_df,\n",
    "    x_col=\"File Path\",\n",
    "    y_cols=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_image_size=IMAGE_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FCVCRw6ncvsX",
   "metadata": {
    "id": "FCVCRw6ncvsX"
   },
   "source": [
    "Tasks:\n",
    "\n",
    "\n",
    "1.   Create 3 test generators: 1 with all examples, 1 with only female, 1 with only male\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae19cb-d890-423c-bf77-15aec6a85b79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84ae19cb-d890-423c-bf77-15aec6a85b79",
    "outputId": "1c1851b5-a623-4dc2-ac9d-cd3b50d8e1f6"
   },
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(val_df, test_df, train_df, x_col, y_cols, sample_size, batch_size, target_image_size, seed=2021):\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        x_col=x_col, \n",
    "        y_col=y_cols, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=target_image_size\n",
    "    )\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True,\n",
    "    )\n",
    "    \n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get valid generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col=x_col,\n",
    "        y_col=y_cols,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        seed=seed,\n",
    "        target_size=target_image_size,\n",
    "    )\n",
    "    \n",
    "    ## create 3 test generator: 1 with all examples, 1 with only female, 1 with only male\n",
    "    ## START\n",
    "\n",
    "    test_generator_F =\n",
    "    \n",
    "    test_generator_M =\n",
    "    \n",
    "    test_generator =\n",
    "    ## END\n",
    "    return valid_generator, test_generator_F, test_generator_M, test_generator\n",
    "\n",
    "val_generator, test_generator_F, test_generator_M, test_generator = get_test_and_valid_generator(\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    train_df=train_df,\n",
    "    x_col=\"File Path\",\n",
    "    y_cols=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_image_size=IMAGE_SIZE,\n",
    "    sample_size=100,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b142680-d90b-4e8f-a871-63a40e533660",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "3b142680-d90b-4e8f-a871-63a40e533660",
    "outputId": "8e6f1a63-b54e-497a-aaa8-b2ab0e633136"
   },
   "outputs": [],
   "source": [
    "x_f, y_f = test_generator_F.__getitem__(0)\n",
    "x_m, y_m = test_generator_M.__getitem__(0)\n",
    "\n",
    "samples = 3\n",
    "columns = 2\n",
    "rows = samples\n",
    "\n",
    "id2cat = {1:'No finding', 0:'Pneumotorax'}\n",
    "fig = plt.figure(figsize=(10, 5*rows))\n",
    "for i in range(0, rows*columns, columns):\n",
    "    label_f = id2cat[y_f[i]]\n",
    "    label_m = id2cat[y_m[i]]\n",
    "    img_f = tf.keras.preprocessing.image.array_to_img(x_f[i//columns])\n",
    "    img_m = tf.keras.preprocessing.image.array_to_img(x_m[i//columns])\n",
    "\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    plt.imshow(img_f)\n",
    "    plt.title('{} - female'.format(label_f))\n",
    "    plt.axis(False)\n",
    "    \n",
    "    fig.add_subplot(rows, columns, i+2)\n",
    "    plt.imshow(img_m)\n",
    "    plt.title('{} - male'.format(label_m))\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8d9c43-d9f2-4779-96e4-1c52c38982a8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "id": "8c8d9c43-d9f2-4779-96e4-1c52c38982a8",
    "outputId": "277357c7-438c-4c6d-a6db-7e16734eda41"
   },
   "outputs": [],
   "source": [
    "neg, pos = np.bincount(train_df[LABELS])\n",
    "total = neg + pos\n",
    "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "    total, pos, 100 * pos / total))\n",
    "\n",
    "(train_df['Finding Labels'].value_counts()/len(train_df)*100).plot(kind='bar',\n",
    "  title='Percentage of different conditions in train dataset',\n",
    "  xlabel='Conditions',\n",
    "  ylabel='Percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeI_Ulvd3Bo",
   "metadata": {
    "id": "1aeI_Ulvd3Bo"
   },
   "source": [
    "Tasks:\n",
    "\n",
    "\n",
    "1.   Calculate weights for classes and store them in dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfda302-21d5-41d5-9ab2-6a929f1b89c4",
   "metadata": {
    "id": "fdfda302-21d5-41d5-9ab2-6a929f1b89c4"
   },
   "outputs": [],
   "source": [
    "## Calculate weights for classes and store them in dict\n",
    "def create_class_weight(y, pos, neg, total):\n",
    "    ## START\n",
    "    \n",
    "    ## END\n",
    "    return class_weight\n",
    "\n",
    "class_weight = create_class_weight(train_df[LABELS], pos, neg, total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gmDNCQCcfB_i",
   "metadata": {
    "id": "gmDNCQCcfB_i"
   },
   "source": [
    "Tasks:\n",
    "\n",
    "\n",
    "1. Define METRICS using tf.keras.metrics\n",
    "2. Initial guesses are not good, we know dataset is imbalanced. Set the output layer's bias to reflect that. Derive initial bias $b_0$ from: $p_0=\\frac{neg}{(pos+neg)}=\\frac{1}{1+e^{-b_0}}$ and add it to the last Dense layer as bias_initializer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783694f-1261-4876-85fb-b3a93ab34e5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8783694f-1261-4876-85fb-b3a93ab34e5f",
    "outputId": "efafccc8-9c81-4613-bd52-7b86e3691467"
   },
   "outputs": [],
   "source": [
    "## Define METRICS using tf.keras.metrics\n",
    "\n",
    "METRICS = [\n",
    "    ## START\n",
    "    \n",
    "    ## END\n",
    "]\n",
    "\n",
    "## Set the output layer's bias to reflect class imbalance\n",
    "## START\n",
    "initial_bias =\n",
    "## END\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "    if output_bias is not None:\n",
    "        output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Conv2D(64,(3,3),padding='same',input_shape=(*IMAGE_SIZE, 3)),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Conv2D(32,(3,3)),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(256),\n",
    "        tf.keras.layers.Activation('relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid',\n",
    "          ## START\n",
    "          \n",
    "          ## END\n",
    "    ])\n",
    "    lr = 1e-4\n",
    "    loss = tf.keras.losses.BinaryCrossentropy()\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr), \n",
    "        loss=loss,\n",
    "        metrics=METRICS,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = make_model(output_bias=initial_bias)\n",
    "initial_weights = 'initial_weights'\n",
    "model.save_weights(initial_weights)\n",
    "\n",
    "model_1 = make_model()\n",
    "model_1.load_weights(initial_weights)\n",
    "model_2_class = make_model()\n",
    "model_2_class.load_weights(initial_weights)\n",
    "model_2_class.layers[-1].bias.assign([0.0])\n",
    "model_3_class_sample = make_model()\n",
    "model_3_class_sample.load_weights(initial_weights)\n",
    "model_3_class_sample.layers[-1].bias.assign([0.0])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936a8bb4-19d9-43d2-b417-351245ddf0e2",
   "metadata": {
    "id": "936a8bb4-19d9-43d2-b417-351245ddf0e2"
   },
   "outputs": [],
   "source": [
    "def train_generator_sample_weights():\n",
    "    batch = 0\n",
    "    for s in train_generator:\n",
    "        sample_weights = np.array(train_df[BATCH_SIZE*batch:(batch+1)*BATCH_SIZE]['sample weight'])\n",
    "        if len(sample_weights) < len(s[0]):\n",
    "            sample_weights_tmp = np.ones((64))\n",
    "            sample_weights_tmp[:len(sample_weights)] = sample_weights\n",
    "            sample_weights = sample_weights_tmp\n",
    "        if len(sample_weights) > len(s[0]):\n",
    "            sample_weights = sample_weights[:len(s[0])]\n",
    "        batch += 1\n",
    "        if batch > len(train_generator):\n",
    "            batch = 0\n",
    "        yield (s[0], s[1], sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61753e4-77a2-440f-9530-a26b012a3a6d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c61753e4-77a2-440f-9530-a26b012a3a6d",
    "outputId": "04532afc-1b88-4453-ef6a-b5972bf33e2e"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_auc', \n",
    "    verbose=1,\n",
    "    patience=2,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs = EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "history_2_class = model_2_class.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs = EPOCHS,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "history_3_class_sample = model_3_class_sample.fit(\n",
    "    train_generator_sample_weights(),\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs = EPOCHS,\n",
    "    callbacks=[early_stopping],\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c6e59a-10b6-4f19-abe2-c61ba7195316",
   "metadata": {
    "id": "f5c6e59a-10b6-4f19-abe2-c61ba7195316"
   },
   "outputs": [],
   "source": [
    "def visualize_training(*args, lw=3):\n",
    "    fig, axs = plt.subplots(len(args), 2)\n",
    "    fig.set_size_inches(12, len(args)*5)\n",
    "\n",
    "    row = 0\n",
    "    for history, name in args:\n",
    "        axs[row, 0].plot(history.history['auc'], label = 'training', marker = '*', linewidth = lw)\n",
    "        axs[row, 0].plot(history.history['val_auc'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "        axs[row, 0].set_title('{} - Training Accuracy vs Validation Accuracy'.format(name))\n",
    "\n",
    "        axs[row, 1].plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "        axs[row, 1].plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "        axs[row, 1].set_title('{} - Training Loss vs Validation Loss'.format(name))\n",
    "        row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313409dc-089e-4cb7-b19b-3ebf0988a920",
   "metadata": {
    "id": "313409dc-089e-4cb7-b19b-3ebf0988a920"
   },
   "outputs": [],
   "source": [
    "visualize_training((history_1, 'history_1'), (history_2_class, 'history_2_class'), (history_3_class_sample, 'history_3_sample'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b3a77-3031-4fea-add9-b1f77225e579",
   "metadata": {
    "id": "b77b3a77-3031-4fea-add9-b1f77225e579"
   },
   "outputs": [],
   "source": [
    "predicted_vals_F_1 = model_1.predict(test_generator_F, steps=len(test_generator_F))\n",
    "predicted_vals_M_1 = model_1.predict(test_generator_M, steps=len(test_generator_M))\n",
    "predicted_vals_1 = model_1.predict(test_generator, steps=len(test_generator))\n",
    "\n",
    "predicted_vals_F_2_class = model_2_class.predict(test_generator_F, steps=len(test_generator_F))\n",
    "predicted_vals_M_2_class = model_2_class.predict(test_generator_M, steps=len(test_generator_M))\n",
    "predicted_vals_2 = model_2_class.predict(test_generator, steps=len(test_generator))\n",
    "\n",
    "predicted_vals_F_3_class_sample = model_3_class_sample.predict(test_generator_F, steps=len(test_generator_F))\n",
    "predicted_vals_M_3_class_sample = model_3_class_sample.predict(test_generator_M, steps=len(test_generator_M))\n",
    "predicted_vals_3 = model_3_class_sample.predict(test_generator, steps=len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0e20c-989d-4e90-91eb-97cc2b532ee1",
   "metadata": {
    "id": "e4c0e20c-989d-4e90-91eb-97cc2b532ee1"
   },
   "outputs": [],
   "source": [
    "def get_roc_curve(labels, *args):\n",
    "\n",
    "    fig, axs = plt.subplots(1, len(args))\n",
    "    fig.set_size_inches(15, 3)\n",
    "\n",
    "    for idx, (predicted_vals, generator, name, sample_weight) in enumerate(args):\n",
    "        auc_roc_vals = []\n",
    "        gt = generator.labels[:]\n",
    "        pred = predicted_vals[:]\n",
    "        auc_roc = roc_auc_score(gt, pred, sample_weight=sample_weight)\n",
    "        auc_roc_vals.append(auc_roc)\n",
    "        fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n",
    "        \n",
    "        axs[idx].plot([0, 1], [0, 1], 'k--')\n",
    "        axs[idx].plot(fpr_rf, tpr_rf, label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n",
    "        axs[idx].set_title('ROC curve ' + name)\n",
    "        axs[idx].legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f84b9-93a7-4b39-8000-47ce10de7496",
   "metadata": {
    "id": "389f84b9-93a7-4b39-8000-47ce10de7496"
   },
   "outputs": [],
   "source": [
    "get_roc_curve(\n",
    "    LABELS,\n",
    "    (predicted_vals_F_1, test_generator_F, 'predicted_vals_F_saved_model_1', None),\n",
    "    (predicted_vals_M_1, test_generator_M, 'predicted_vals_M_saved_model_1', None),\n",
    "    (predicted_vals_1, test_generator, 'predicted_vals_saved_model_1', None),\n",
    ")\n",
    "\n",
    "get_roc_curve(\n",
    "    LABELS,\n",
    "    (predicted_vals_F_2_class, test_generator_F, 'predicted_vals_F_saved_model_2', None),\n",
    "    (predicted_vals_M_2_class, test_generator_M, 'predicted_vals_M_saved_model_2', None),\n",
    "    (predicted_vals_2, test_generator, 'predicted_vals_saved_model_2', None),\n",
    ")\n",
    "\n",
    "get_roc_curve(\n",
    "    LABELS,\n",
    "    (predicted_vals_F_3_class_sample, test_generator_F, 'predicted_vals_F_saved_model_3', None),\n",
    "    (predicted_vals_M_3_class_sample, test_generator_M, 'predicted_vals_M_saved_model_3', None),\n",
    "    (predicted_vals_3, test_generator, 'predicted_vals_saved_model_3', None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3Wo7ihx_qY6W",
   "metadata": {
    "id": "3Wo7ihx_qY6W"
   },
   "outputs": [],
   "source": [
    "class PatientGender:\n",
    "    FEMALE = 1\n",
    "    MALE = 0\n",
    "\n",
    "def pr_curve(df, labels, gender, predicted_vals, title, use_sample_weight=False):\n",
    "    if gender != None:\n",
    "        df_gender = df[df['Patient Gender'] == gender]\n",
    "    else:\n",
    "        df_gender = df\n",
    "\n",
    "    predicted_vals_class = predicted_vals[:]\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(\n",
    "        df_gender['No Finding'],\n",
    "        predicted_vals_class,\n",
    "        sample_weight=df_gender['sample weight'] if use_sample_weight else None,\n",
    "    )\n",
    "    plt.plot(recall, precision, label='PR')\n",
    "    pscore = average_precision_score(\n",
    "        df_gender['No Finding'],\n",
    "        predicted_vals_class,\n",
    "        sample_weight=df_gender['sample weight'] if use_sample_weight else None,\n",
    "    )\n",
    "    \n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('PR Curve - {} - {}'.format(title, pscore))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pr_curve(test_df, LABELS, None, predicted_vals_1, 'predicted_vals')\n",
    "pr_curve(test_df, LABELS, None, predicted_vals_2, 'predicted_vals_class')\n",
    "pr_curve(test_df, LABELS, None, predicted_vals_3, 'predicted_vals_sample' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-IENk96j_s7X",
   "metadata": {
    "id": "-IENk96j_s7X"
   },
   "outputs": [],
   "source": [
    "DOWNLOADED_MODELS_TAR = 'downloaded_models.tar.gz'\n",
    "DOWNLOADED_MODELS = 'downloaded_models'\n",
    "DOWNLOADED_TESTSET = 'downloaded_testset.csv'\n",
    "\n",
    "if not os.path.exists(DOWNLOADED_MODELS_TAR):\n",
    "    ! gdown --id 1-5LnBA8PzUt9JqpnggV6SBwmQeK7Spax -O $DOWNLOADED_MODELS_TAR\n",
    "else:\n",
    "    print('Images archive file ({}) already exists.'.format(DOWNLOADED_MODELS_TAR))\n",
    "\n",
    "if not os.path.exists(DOWNLOADED_MODELS):\n",
    "    ! mkdir $DOWNLOADED_MODELS\n",
    "    ! tar -xzf $DOWNLOADED_MODELS_TAR --directory $DOWNLOADED_MODELS\n",
    "    print('Unpacked to {}'.format(DOWNLOADED_MODELS))\n",
    "else:\n",
    "    print('Images have already been unpacked ({}).'.format(DOWNLOADED_MODELS))\n",
    "\n",
    "if not os.path.exists(DOWNLOADED_TESTSET):\n",
    "    ! gdown --id 1-5YDbJfrxVaYdSHPxBw9XxjGnsrtCdjP -O $DOWNLOADED_TESTSET\n",
    "else:\n",
    "    print('Test file ({}) already exists.'.format(DOWNLOADED_TESTSET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UsWRMhSe29FY",
   "metadata": {
    "id": "UsWRMhSe29FY"
   },
   "outputs": [],
   "source": [
    "test_df_saved = pd.read_csv(DOWNLOADED_TESTSET)\n",
    "test_df_saved['Patient_Gender_ID'] = test_df_saved['Patient Gender']\n",
    "val_generator_saved, test_generator_F_saved, test_generator_M_saved, test_generator_saved = get_test_and_valid_generator(\n",
    "    val_df=val_df,\n",
    "    test_df=test_df_saved,\n",
    "    train_df=train_df,\n",
    "    x_col=\"File Path\",\n",
    "    y_cols=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    target_image_size=IMAGE_SIZE,\n",
    "    sample_size=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MiBaHclDGOg4",
   "metadata": {
    "id": "MiBaHclDGOg4"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(DOWNLOADED_MODELS+'/saved_models/model_1/save_weights')\n",
    "pv_F = model.predict(test_generator_F_saved, steps=len(test_generator_F_saved))\n",
    "pv_M = model.predict(test_generator_M_saved, steps=len(test_generator_M_saved))\n",
    "pv = model.predict(test_generator_saved, steps=len(test_generator_saved))\n",
    "\n",
    "pr_curve(test_df_saved, LABELS, None, pv, 'predicted_vals')\n",
    "get_roc_curve(\n",
    "    LABELS,\n",
    "    (pv_F, test_generator_F_saved, 'predicted_vals_F', None),\n",
    "    (pv_M, test_generator_M_saved, 'predicted_vals_M', None),\n",
    "    (pv, test_generator_saved, 'predicted_vals', None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swVD1_HIkaTS",
   "metadata": {
    "id": "swVD1_HIkaTS"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(DOWNLOADED_MODELS+'/saved_models/model_2/save_weights')\n",
    "pv_F = model.predict(test_generator_F_saved, steps=len(test_generator_F_saved))\n",
    "pv_M = model.predict(test_generator_M_saved, steps=len(test_generator_M_saved))\n",
    "pv = model.predict(test_generator_saved, steps=len(test_generator_saved))\n",
    "\n",
    "pr_curve(test_df_saved, LABELS, None, pv, 'predicted_vals_class')\n",
    "get_roc_curve(\n",
    "    LABELS,\n",
    "    (pv_F, test_generator_F_saved, 'predicted_vals_F_class', None),\n",
    "    (pv_M, test_generator_M_saved, 'predicted_vals_M_class', None),\n",
    "    (pv, test_generator_saved, 'predicted_vals_class', None),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g5Dd2X3ukgCw",
   "metadata": {
    "id": "g5Dd2X3ukgCw"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(DOWNLOADED_MODELS+'/saved_models/model_3/save_weights')\n",
    "pv_F = model.predict(test_generator_F_saved, steps=len(test_generator_F_saved))\n",
    "pv_M = model.predict(test_generator_M_saved, steps=len(test_generator_M_saved))\n",
    "pv = model.predict(test_generator_saved, steps=len(test_generator_saved))\n",
    "\n",
    "pr_curve(test_df_saved, LABELS, None, pv, 'predicted_vals_sample')\n",
    "get_roc_curve(\n",
    "    LABELS,\n",
    "    (pv_F, test_generator_F_saved, 'predicted_vals_F_sample', None),\n",
    "    (pv_M, test_generator_M_saved, 'predicted_vals_M_sample', None),\n",
    "    (pv, test_generator_saved, 'predicted_vals_sample', None),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "5_imbalanced_data",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
