{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9337108c",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/issondl/from-data-to-solution-2021/blob/main/3_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "akR0X0xrjnls",
   "metadata": {
    "id": "akR0X0xrjnls"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Rtc27eZjk6N3",
   "metadata": {
    "id": "Rtc27eZjk6N3"
   },
   "source": [
    "## Check for acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7fde9-9eb1-4ee1-bb94-0e23583a5456",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "02e7fde9-9eb1-4ee1-bb94-0e23583a5456",
    "outputId": "1ec1c594-6591-4dc4-c64c-abdd110df5db"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PamIzhSQjp6W",
   "metadata": {
    "id": "PamIzhSQjp6W"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a558e6-ebc1-4f4e-b5be-ad279c66383c",
   "metadata": {
    "id": "d8a558e6-ebc1-4f4e-b5be-ad279c66383c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2021)\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(2021)\n",
    "import random\n",
    "random.seed(2021)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow.keras.layers as L\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
    "from tqdm import tqdm\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "set_verbosity(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05nbvwvlmMbf",
   "metadata": {
    "id": "05nbvwvlmMbf"
   },
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d188b56-405b-4e3e-b4de-2378c10fcb7f",
   "metadata": {
    "id": "6d188b56-405b-4e3e-b4de-2378c10fcb7f"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = 'data/'\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "CSV_FILE = os.path.join(DATA_DIR, 'nih_chest_xray_single_9c_bb_onehot.csv')\n",
    "IMAGES_ARCHIVE_FILE = os.path.join(DATA_DIR, 'nih_chest_xray_single_9c_256x256.tar.gz')\n",
    "IMAGES_DIR = os.path.join(DATA_DIR, 'images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1005de15-ff10-40b5-9e3a-7776263b2b4f",
   "metadata": {
    "id": "1005de15-ff10-40b5-9e3a-7776263b2b4f"
   },
   "source": [
    "## Download the prepared dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9a44e8-f014-4666-a1b4-ae8bad970d03",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4b9a44e8-f014-4666-a1b4-ae8bad970d03",
    "outputId": "308cffdc-7728-4dad-9704-323ba0de8fc1"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(CSV_FILE):\n",
    "    ! gdown --id 1i7oUN9QTjOavTPGgvWKq22InrTFN6mYH -O $CSV_FILE\n",
    "else:\n",
    "    print('CSV file ({}) already exists.'.format(CSV_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca02cbc3-1759-4ff5-9d80-4b1449620a34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ca02cbc3-1759-4ff5-9d80-4b1449620a34",
    "outputId": "166df7f8-6814-49e0-e931-de00856dc5df"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_ARCHIVE_FILE):\n",
    "    ! gdown --id 1Cg7dbE1tWSBvdTfGc0G272SA_j_XocOW -O $IMAGES_ARCHIVE_FILE\n",
    "else:\n",
    "    print('Images archive file ({}) already exists.'.format(IMAGES_ARCHIVE_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e6a44-e2fb-4131-a2b8-80d7f275397a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0b7e6a44-e2fb-4131-a2b8-80d7f275397a",
    "outputId": "b91cd529-501c-47a6-d88c-0d2dca0d2a55"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(IMAGES_DIR):\n",
    "    ! tar -xzf $IMAGES_ARCHIVE_FILE\n",
    "    print('Unpacked to {}'.format(IMAGES_DIR))\n",
    "else:\n",
    "    print('Images have already been unpacked ({}).'.format(IMAGES_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IEIdMf0Vmhp6",
   "metadata": {
    "id": "IEIdMf0Vmhp6"
   },
   "source": [
    "## Explore the dataset\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Read the CSV file and explore the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e63851-6458-4de5-aab7-619ff7dc2c64",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "54e63851-6458-4de5-aab7-619ff7dc2c64",
    "outputId": "8d72a178-af96-4480-82ef-0001a901c4aa"
   },
   "outputs": [],
   "source": [
    "## Read the CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c2a26-2a30-4add-af30-66b4154c958d",
   "metadata": {
    "id": "b90c2a26-2a30-4add-af30-66b4154c958d"
   },
   "source": [
    "### Prepare Data for Training and Testing\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Create new dataframe with only 'Pneumothorax' and 'Mass' labels.\n",
    "2. Split the two-class dataframe into train, validation and test dataframes with `train_test_split`. Each call will split the data into two, so we need to call it twice to get `train`, `val` and `test` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SBQtcft50bvd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "SBQtcft50bvd",
    "outputId": "f77e6915-a182-4143-c785-489fcada8f51"
   },
   "outputs": [],
   "source": [
    "## Create new dataframe with only 'Pneumothorax' and 'Mass' labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L5Mc8ifw8lN4",
   "metadata": {
    "id": "L5Mc8ifw8lN4"
   },
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.15\n",
    "VAL_SIZE = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37788204-24c1-457a-92e8-3436b393aa46",
   "metadata": {
    "id": "37788204-24c1-457a-92e8-3436b393aa46"
   },
   "outputs": [],
   "source": [
    "## Split the two-class dataframe into train, validation and test dataframes with\n",
    "## `train_test_split`. Each call will split the data into two, so we need to call\n",
    "## it twice to get `train`, `val` and `test` sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ArriPIFg1jyg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArriPIFg1jyg",
    "outputId": "5358ad4d-3ca0-41e0-e2df-ab3b8bc1ff85"
   },
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(train_df))\n",
    "print(len(val_df))\n",
    "print(len(test_df))\n",
    "print()\n",
    "print(len(train_df)/len(df)*100)\n",
    "print(len(val_df)/len(df)*100)\n",
    "print(len(test_df)/len(df)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VGr5b-24HTrU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "VGr5b-24HTrU",
    "outputId": "3df3c337-d78d-4532-f2b1-fd6b7a6ef601"
   },
   "outputs": [],
   "source": [
    "print(train_df['Finding Labels'].value_counts())\n",
    "train_df['Finding Labels'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "p6SUWhbq9XnA",
   "metadata": {
    "id": "p6SUWhbq9XnA"
   },
   "source": [
    "## Create data pipeline\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Create data pipeline for training\n",
    "   \n",
    "   Use `ImageDataGenerator` and `flow_from_dataframe` to build an image pre-processing pipeline that will feed training with structured data.\n",
    "\n",
    "1. Create data pipeline for testing and validation\n",
    "\n",
    "  Do the same for testing and validation. You should also compute quantities required for featurewise normalization (like mean and standard deviation) on training data and fit test/validation generators on it.\n",
    "\n",
    "Useful resources:\n",
    "\n",
    "* https://keras.io/api/preprocessing/image/\n",
    "* https://fairyonice.github.io/Learn-about-ImageDataGenerator.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca0b6c1-46c0-4c20-b028-6377ddd09182",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eca0b6c1-46c0-4c20-b028-6377ddd09182",
    "outputId": "d60227bd-df03-4310-d3ea-8020ae7ed092"
   },
   "outputs": [],
   "source": [
    "## Create data pipeline for training\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_SIZE = [128, 128]\n",
    "\n",
    "def get_train_generator(df, labels, batch_size, image_size,\n",
    "                        color_mode='grayscale', file_path_col='File Path'):\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,  # Set each sample mean to 0.\n",
    "        samplewise_std_normalization=True,  # Divide each input by its std\n",
    "        rotation_range=5,  # Degree range for random rotations\n",
    "        width_shift_range=0.1,  # fraction of total width\n",
    "        height_shift_range=0.05,  # fraction of total height\n",
    "        shear_range=0.1,  # Shear Intensity (Shear angle in counter-clockwise direction in degrees)\n",
    "        zoom_range=0.15,  # Range for random zoom\n",
    "        fill_mode='reflect',  # fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}\n",
    "        horizontal_flip=True,  # Randomly flip inputs horizontally.\n",
    "        vertical_flip=False,  # Randomly flip inputs vertically.\n",
    "    )\n",
    "\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=df,  # Pandas dataframe containing the filepaths relative to directory (or absolute paths if directory is None)\n",
    "        x_col=file_path_col,  # column in dataframe that contains the filenames\n",
    "        y_col=labels,  # string or list, column/s in dataframe that has the target data.\n",
    "        class_mode='raw',  # \"raw\": numpy array of values in y_col column(s)\n",
    "        batch_size=batch_size,  # size of the batches of data\n",
    "        shuffle=True,  # whether to shuffle the data (default: True)\n",
    "        seed=2021,  # optional random seed for shuffling and transformations.\n",
    "        target_size=image_size,  # tuple of integers (height, width), default: (256, 256). The dimensions to which all images found will be resized.\n",
    "        color_mode=color_mode,  # one of \"grayscale\", \"rgb\", \"rgba\"\n",
    "    )\n",
    "    return generator\n",
    "\n",
    "train_generator = get_train_generator(\n",
    "    df=train_df,\n",
    "    labels=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ab1f62-d7d6-45e6-a1dc-bd8d7c3c1cf8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 294
    },
    "id": "e1ab1f62-d7d6-45e6-a1dc-bd8d7c3c1cf8",
    "outputId": "8a9bcb25-65ee-4ee9-aad7-3596d2703d9c"
   },
   "outputs": [],
   "source": [
    "def get_label(label_encoding, labels):\n",
    "    for i, val in enumerate(label_encoding):\n",
    "        if val:\n",
    "            return labels[i]\n",
    "    return 'No Label'\n",
    "\n",
    "x, y = train_generator.__getitem__(0)\n",
    "\n",
    "samples = 2\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "for i in range(samples):\n",
    "    label = get_label(y[i], LABELS)\n",
    "    img_processed = x[i].squeeze()\n",
    "\n",
    "    fig.add_subplot(samples, i+1, 1)\n",
    "    plt.imshow(img_processed, cmap='gray')\n",
    "    plt.title('{}'.format(label))\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae19cb-d890-423c-bf77-15aec6a85b79",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84ae19cb-d890-423c-bf77-15aec6a85b79",
    "outputId": "65f63a03-0756-4c8f-c49c-64402a51988a"
   },
   "outputs": [],
   "source": [
    "## Create data pipeline for testing and validation\n",
    "def get_test_and_valid_generator(val_df, test_df, train_df, labels, batch_size, image_size,\n",
    "                                 color_mode='grayscale', file_path_col='File Path'):\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        x_col=file_path_col,\n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=100,  # sample size, we will be loading only the first batch\n",
    "        shuffle=True,\n",
    "        seed=2021,\n",
    "        target_size=image_size,\n",
    "        color_mode=color_mode,\n",
    "    )\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next()\n",
    "    data_sample = batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True\n",
    "    )\n",
    "    \n",
    "    # fit generator to sample from training data\n",
    "    image_generator.fit(data_sample)\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=val_df,\n",
    "        x_col=file_path_col,\n",
    "        y_col=labels,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=image_size,\n",
    "        color_mode=color_mode,\n",
    "    )\n",
    "\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "        dataframe=test_df,\n",
    "        x_col=file_path_col,\n",
    "        y_col=labels,\n",
    "        class_mode=\"raw\",\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        target_size=image_size,\n",
    "        color_mode=color_mode,\n",
    "    )\n",
    "    return valid_generator, test_generator\n",
    "\n",
    "val_generator, test_generator= get_test_and_valid_generator(\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    train_df=train_df,\n",
    "    labels=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YLxACjJ4HdEi",
   "metadata": {
    "id": "YLxACjJ4HdEi"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_hWqksxs_wzR",
   "metadata": {
    "id": "_hWqksxs_wzR"
   },
   "outputs": [],
   "source": [
    "def visualize_training(history):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth=3)\n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth=3)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth=3)\n",
    "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth=3)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6XeMVVIoBEiy",
   "metadata": {
    "id": "6XeMVVIoBEiy"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NickoC2Z2WRM",
   "metadata": {
    "id": "NickoC2Z2WRM"
   },
   "source": [
    "### Shallow Model\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Create a shallow model based on LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8783694f-1261-4876-85fb-b3a93ab34e5f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "8783694f-1261-4876-85fb-b3a93ab34e5f",
    "outputId": "cf3f5781-6379-4124-b98e-0b1eba8666ce"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "##\n",
    "\n",
    "model_1 = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        ## START\n",
    "\n",
    "        ## END\n",
    "    ],\n",
    "    name='Model_Shallow',\n",
    ")\n",
    "\n",
    "model_1.compile(\n",
    "    ## START\n",
    "\n",
    "    ## END\n",
    ")\n",
    "\n",
    "history_1 = model_1.fit(\n",
    "    ## START\n",
    "\n",
    "    ## END\n",
    ")\n",
    "\n",
    "visualize_training(history_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cPhYfYHOuu",
   "metadata": {
    "id": "04cPhYfYHOuu"
   },
   "source": [
    "### Regularization\n",
    "\n",
    "Tasks:\n",
    "1. try to fix model's poor performance using common regularization techniques - dropout and L1/L2 regularization\n",
    "\n",
    "Useful resources:\n",
    "\n",
    "* https://keras.io/api/layers/regularization_layers/dropout/\n",
    "* https://keras.io/api/layers/regularizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-7OnoyliAGk9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-7OnoyliAGk9",
    "outputId": "5300e1e3-6506-43ea-98e5-99222af876aa"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "##\n",
    "\n",
    "model_dropout = tf.keras.Sequential(\n",
    "    layers = [\n",
    "        ## START\n",
    "\n",
    "        ## END\n",
    "    ],\n",
    "    name='Model_Dropout',\n",
    ")\n",
    "\n",
    "model_dropout.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy'],\n",
    ")\n",
    "\n",
    "history_dropout = model_dropout.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "visualize_training(history_dropout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IYJmR6YMAR6g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IYJmR6YMAR6g",
    "outputId": "63ec52c6-776f-4adb-8f52-8b13413bd9ba"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from tensorflow.keras.regularizers import l1_l2 as L1L2\n",
    "from tensorflow.keras.regularizers import l2 as L2\n",
    "\n",
    "model_reg = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        ## START\n",
    "\n",
    "        ## END\n",
    "    ],\n",
    "    name='Model_Regularization',\n",
    ")\n",
    "\n",
    "model_reg.summary()\n",
    "\n",
    "model_reg.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics = ['accuracy'],\n",
    ")\n",
    "\n",
    "history_reg = model_reg.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs=EPOCHS,\n",
    ")\n",
    "\n",
    "visualize_training(history_reg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6wOrbaPxHFQ6",
   "metadata": {
    "id": "6wOrbaPxHFQ6"
   },
   "source": [
    "### Early Stopping\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. Try to reduce training time by using early stopping once model reaches satisfactory performance\n",
    "\n",
    "Useful resources:\n",
    "\n",
    "* https://keras.io/api/callbacks/early_stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OUDnnyOQBI5I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OUDnnyOQBI5I",
    "outputId": "29b838e8-925f-410d-c6ab-8c2face8ed13"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model_earlystop = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        L.Conv2D(filters=32, kernel_size=(5, 5), activation='relu', input_shape=(*IMAGE_SIZE, 1)),\n",
    "        L.MaxPool2D(),\n",
    "        L.Conv2D(filters=48, kernel_size=(5, 5), activation='relu'),\n",
    "        L.MaxPool2D(),\n",
    "        L.Flatten(),\n",
    "        L.Dense(units=256, activation='relu',\n",
    "                kernel_regularizer=L1L2(l1=1e-5, l2=1e-4),\n",
    "                activity_regularizer=L2(1e-5)\n",
    "        ),\n",
    "        L.Dropout(0.2),\n",
    "        L.Dense(units=84, activation='relu',\n",
    "                kernel_regularizer=L1L2(l1=1e-5, l2=1e-4),\n",
    "                activity_regularizer=L2(1e-5)\n",
    "        ),\n",
    "        L.Dropout(0.2),\n",
    "        L.Dense(len(LABELS), activation='softmax'),\n",
    "    ],\n",
    "    name='Model_EarlyStop'\n",
    ")\n",
    "\n",
    "model_earlystop.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "## START\n",
    "early_stopping_custom =\n",
    "\n",
    "## END\n",
    "\n",
    "history_earlystop = model_earlystop.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs=EPOCHS,\n",
    "    ## START\n",
    "    \n",
    "    ## END\n",
    ")\n",
    "\n",
    "visualize_training(history_earlystop)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71IXqLi4G_IB",
   "metadata": {
    "id": "71IXqLi4G_IB"
   },
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Tasks:\n",
    "\n",
    "1. To furtherly improve model's performance change the approach - instead of implementing your own model and training from scratch use existing model with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IJZpzV-jHBGV",
   "metadata": {
    "id": "IJZpzV-jHBGV"
   },
   "outputs": [],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ralsFz8yHxkM",
   "metadata": {
    "id": "ralsFz8yHxkM"
   },
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjqSpW1rINgT",
   "metadata": {
    "id": "AjqSpW1rINgT"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [240, 240]  # https://keras.io/examples/vision/image_classification_efficientnet_fine_tuning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jq7DEfBcIZi5",
   "metadata": {
    "id": "jq7DEfBcIZi5"
   },
   "outputs": [],
   "source": [
    "model_transfer = tf.keras.Sequential(\n",
    "    layers=[\n",
    "        ## START\n",
    "\n",
    "        ## END\n",
    "    ],\n",
    "    name='Model_TransferLearning',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UTKV_5IJmDQ_",
   "metadata": {
    "id": "UTKV_5IJmDQ_"
   },
   "outputs": [],
   "source": [
    "model_transfer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DudOBiMorAdg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DudOBiMorAdg",
    "outputId": "d93bada6-e518-4ef1-93c6-55f979d75b9e"
   },
   "outputs": [],
   "source": [
    "train_generator = get_train_generator(\n",
    "    df = train_df,\n",
    "    file_path_col=\"File Path\",\n",
    "    labels=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode='rgb',\n",
    ")\n",
    "\n",
    "val_generator, test_generator= get_test_and_valid_generator(\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    train_df=train_df,\n",
    "    file_path_col=\"File Path\",\n",
    "    labels=LABELS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    color_mode='rgb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NPzv5hGlc_pM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "NPzv5hGlc_pM",
    "outputId": "3046a667-a609-4dc0-e499-e7b77d578802"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "YouTubeVideo('QIlR0rX3Zx8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OVjK7DGEn9Fo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "OVjK7DGEn9Fo",
    "outputId": "dd2b91e2-5de8-498f-c736-c4cfcc584406"
   },
   "outputs": [],
   "source": [
    "history = model_transfer.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator),\n",
    "    epochs=10,\n",
    "    callbacks=[early_stopping_custom],\n",
    ")\n",
    "\n",
    "visualize_training(history)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "3_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
